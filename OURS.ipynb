{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65132e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "from torch import optim\n",
    "\n",
    "class BatchIndex:\n",
    "    def __init__(self, size, batch_size, shuffle=True):\n",
    "        self.index_list = torch.as_tensor([(x, min(x + batch_size, size)) for x in range(0, size, batch_size)])\n",
    "        \n",
    "        if shuffle:\n",
    "            self.index_list = self.index_list[torch.randperm(len(self.index_list))]\n",
    "        \n",
    "        self.pos = -1\n",
    "\n",
    "    def __next__(self):\n",
    "        self.pos += 1\n",
    "        if self.pos >= len(self.index_list):\n",
    "            raise StopIteration\n",
    "        return self.index_list[self.pos]\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.pos = -1\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index_list)\n",
    "    \n",
    "def get_mgrid(sidelen, dim=2, s=1,t=0):\n",
    "    '''Generates a flattened grid of (x,y,...) coordinates in a range of -1 to 1.'''\n",
    "    if isinstance(sidelen, int):\n",
    "        sidelen = dim * (sidelen,)\n",
    "\n",
    "    if dim == 2:\n",
    "        pixel_coords = np.stack(np.mgrid[:sidelen[0]:s, :sidelen[1]:s], axis=-1)[None, ...].astype(np.float32)\n",
    "        pixel_coords[..., 0] = pixel_coords[..., 0] / (sidelen[0] - 1)\n",
    "        pixel_coords[..., 1] = pixel_coords[..., 1] / (sidelen[1] - 1)\n",
    "    elif dim == 3:\n",
    "        ranges = [\n",
    "            torch.arange(0, sidelen[0], s, device='cuda:0'),\n",
    "            torch.arange(0, sidelen[1], s, device='cuda:0'),\n",
    "            torch.arange(0, sidelen[2], s, device='cuda:0'),\n",
    "        ]\n",
    "        grid = torch.meshgrid(ranges, indexing='ij')\n",
    "        pixel_coords = torch.stack(grid, dim=-1)[None, ...].float()\n",
    "        pixel_coords[..., 0] = pixel_coords[..., 0] / (sidelen[0] - 1)\n",
    "        pixel_coords[..., 1] = pixel_coords[..., 1] / (sidelen[1] - 1)\n",
    "        pixel_coords[..., 2] = pixel_coords[..., 2] / (sidelen[2] - 1)\n",
    "    elif dim == 4:\n",
    "        pixel_coords = np.stack(np.mgrid[:sidelen[0]:(t+1), :sidelen[1]:s, :sidelen[2]:s, :sidelen[3]:s], axis=-1)[None, ...].astype(np.float32)\n",
    "        pixel_coords[..., 0] = pixel_coords[..., 0] / max(sidelen[0] - 1, 1)\n",
    "        pixel_coords[..., 1] = pixel_coords[..., 1] / (sidelen[1] - 1)\n",
    "        pixel_coords[..., 2] = pixel_coords[..., 2] / (sidelen[2] - 1)\n",
    "        pixel_coords[..., 3] = pixel_coords[..., 3] / (sidelen[3] - 1)\n",
    "    else:\n",
    "        raise NotImplementedError('Not implemented for dim=%d' % dim)\n",
    "    pixel_coords = 2. * pixel_coords - 1.\n",
    "    pixel_coords = pixel_coords.cpu().numpy().reshape(-1,3, order='F')\n",
    "    return pixel_coords\n",
    "\n",
    "def fast_random_choice(dim, num_samples_per_frame, unique=True, device='cuda:0'):\n",
    "    if unique:\n",
    "        num_samples = num_samples_per_frame * 2  # 防止去重后低于预定采样值\n",
    "        x = torch.randint(\n",
    "                0, dim[0], size=(num_samples,), device='cuda:0'\n",
    "            )\n",
    "        y = torch.randint(\n",
    "                0, dim[1], size=(num_samples,), device='cuda:0'\n",
    "            )\n",
    "        z = torch.randint(\n",
    "                0, dim[2], size=(num_samples,), device='cuda:0'\n",
    "            )\n",
    "        \n",
    "        xyz = torch.stack([x, y, z], dim=-1)\n",
    "        _, index = torch.unique(xyz, dim=0, sorted=False, return_inverse=True)\n",
    "        xyz = xyz[index[:num_samples_per_frame, ...]]\n",
    "        return xyz[...,0], xyz[...,1], xyz[...,2]\n",
    "    else:\n",
    "        x = torch.randint(\n",
    "                0, dim[0], size=(num_samples_per_frame,), device='cuda:0'\n",
    "            )\n",
    "        y = torch.randint(\n",
    "                0, dim[1], size=(num_samples_per_frame,), device='cuda:0'\n",
    "            )\n",
    "        z = torch.randint(\n",
    "                0, dim[2], size=(num_samples_per_frame,), device='cuda:0'\n",
    "            )\n",
    "        xyz = torch.stack([x, y, z], dim=-1)\n",
    "        if device == 'cpu':\n",
    "            xyz = xyz.cpu()\n",
    "        return xyz[...,0], xyz[...,1], xyz[...,2]\n",
    "    \n",
    "def count_params(model):  # 查看模型参数量\n",
    "    param_num = sum(p.numel() for p in model.parameters())\n",
    "    return param_num\n",
    "\n",
    "def cleanup():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bad143eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import threading\n",
    "import queue\n",
    "import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "class ScalarDataSet():\n",
    "    def __init__(self,args, device='cuda:0'):\n",
    "        self.dataset = args.dataset\n",
    "        self.batch_size = args.batch_size\n",
    "        self.interval = args.interval\n",
    "        self.downsample_factor = args.downsample_factor\n",
    "        self.device = device\n",
    "\n",
    "        if self.dataset == 'combustion':\n",
    "            self.dim = [480, 720, 120]\n",
    "            self.total_samples = 1\n",
    "            self.data_path = './dataset/combustion/'        \n",
    "        elif self.dataset == 'fivejets':\n",
    "            self.dim = [128, 128, 128]\n",
    "            self.total_samples = 1\n",
    "            self.data_path = './dataset/fivejets/' \n",
    "        elif self.dataset == 'halfcy':\n",
    "            self.dim = [640, 240, 80]\n",
    "            self.total_samples = 1\n",
    "            self.data_path = './dataset/halfcy/'  \n",
    "        elif self.dataset == 'tornado':\n",
    "            self.dim = [128, 128, 128]\n",
    "            self.total_samples = 1\n",
    "            self.data_path = './dataset/tornado/' \n",
    "        elif self.dataset == 'h2':\n",
    "            self.dim = [600, 248, 248]\n",
    "            self.total_samples = 1\n",
    "            self.data_path = './dataset/h2/' \n",
    "\n",
    "        self.num_workers = 16\n",
    "\n",
    "        self.samples = [i for i in range(1,self.total_samples+1,self.interval+1)]\n",
    "        self.total_samples = self.samples[-1]\n",
    "        self.num_samples_per_frame = (self.dim[0]*self.dim[1]*self.dim[2]//self.downsample_factor)//self.batch_size * self.batch_size\n",
    "        # self.num_samples_per_frame = 4 * self.batch_size\n",
    "        # self.num_samples_per_frame = self.dim[0]*self.dim[1]*self.dim[2]\n",
    "\n",
    "        self.queue_size = 2\n",
    "        self.loader_queue = queue.Queue(maxsize=self.queue_size)  # 限制队列大小为2\n",
    "        self.executor = ThreadPoolExecutor(max_workers=self.queue_size)\n",
    "\n",
    "        if args.mode == 'train':\n",
    "            self.data = self.preload_with_multi_threads(self.load_volume_data, num_workers=self.num_workers, data_str='Volume Data')\n",
    "            self.data = torch.as_tensor(np.asarray(self.data), device=self.device)  # [t个时间步, z, y, x] 需要改成xyz的形式\n",
    "\n",
    "            self.len = self.num_samples_per_frame * len(self.samples)\n",
    "            self._get_data = self._get_training_data\n",
    "\n",
    "            samples = self.dim[2]*self.dim[1]*self.dim[0]\n",
    "            self.coords = get_mgrid([self.dim[0],self.dim[1],self.dim[2]],dim=3)\n",
    "            self.time = np.zeros((samples,1))\n",
    "            self.testing_data_inputs = torch.as_tensor(np.concatenate((self.time, self.coords),axis=1), dtype=torch.float, device='cuda:0')\n",
    "            self.preload_data()\n",
    "\n",
    "        elif args.mode == 'inf':\n",
    "            samples = self.dim[2]*self.dim[1]*self.dim[0]\n",
    "            self.coords = get_mgrid([self.dim[0],self.dim[1],self.dim[2]],dim=3)\n",
    "            self.time = np.zeros((samples,1))\n",
    "            self.testing_data_inputs = torch.as_tensor(np.concatenate((self.time, self.coords),axis=1), dtype=torch.float, device='cuda:0')\n",
    "            # self._get_data = self._get_testing_data\n",
    "            # self.preload_data()\n",
    "\n",
    "    def preload_data(self):\n",
    "        if self.loader_queue.full():\n",
    "            return  # 如果队列已满，不进行加载\n",
    "        self.loader_queue.put(self._get_data())\n",
    "\n",
    "    def get_data(self):\n",
    "        if self.loader_queue.empty():\n",
    "            print(\"DataLoader is not ready yet! Waiting...\")\n",
    "        while self.loader_queue.empty():\n",
    "            pass\n",
    "        # 获取当前 DataLoader 并异步加载下一个\n",
    "        current_data = self.loader_queue.get()\n",
    "        self.executor.submit(self.preload_data)\n",
    "        return current_data\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _get_testing_data(self, idx):\n",
    "        t = idx - 1\n",
    "        t = t / max((self.total_samples-1), 1)\n",
    "        t = 2.0 * t - 1.0\n",
    "        testing_data_inputs = self.testing_data_inputs.clone()\n",
    "        testing_data_inputs[:,0] = t\n",
    "        batchidxgenerator = BatchIndex(testing_data_inputs.shape[0], self.batch_size, False)\n",
    "        return testing_data_inputs, batchidxgenerator\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _get_training_data(self):\n",
    "        training_data_inputs = []\n",
    "        training_data_outputs = []\n",
    "\n",
    "        for i in range(0, len(self.samples)):\n",
    "            x,y,z = fast_random_choice(self.dim, self.num_samples_per_frame)\n",
    "            t = torch.ones_like(x) * (self.samples[i]-1)\n",
    "\n",
    "            outputs = self.data[i, x, y, z]  # 第i个体数据中取xyz, 第i个体数据对应的时间步是t\n",
    "            # 归一化\n",
    "            x = x / (self.dim[0] - 1)\n",
    "            y = y / (self.dim[1] - 1)\n",
    "            z = z / (self.dim[2] - 1)\n",
    "            t = t / max((self.total_samples-1), 1)\n",
    "\n",
    "            inputs = torch.stack([t, x, y, z], dim=-1)\n",
    "            inputs = 2.0 * inputs - 1.0  # 缩放到[-1,1]\n",
    "            training_data_inputs.append(inputs)\n",
    "            training_data_outputs.append(outputs)\n",
    "\n",
    "        training_data_inputs = torch.cat(training_data_inputs, dim=0).cuda()\n",
    "        training_data_outputs = torch.cat(training_data_outputs, dim=0).cuda()\n",
    "        idx = torch.randperm(training_data_inputs.shape[0], device='cpu')\n",
    "        training_data_inputs = training_data_inputs[idx].contiguous()\n",
    "        training_data_outputs = training_data_outputs[idx].contiguous()\n",
    "        batchidxgenerator = BatchIndex(self.len, self.batch_size, shuffle=True)\n",
    "        del idx\n",
    "        cleanup()\n",
    "        return training_data_inputs, training_data_outputs, batchidxgenerator\n",
    "\n",
    "    def load_volume_data(self, idx):\n",
    "        d = np.fromfile(self.data_path+'{:04d}.raw'.format(self.samples[idx]), dtype='<f')\n",
    "        d = 2. * (d - np.min(d)) / (np.max(d) - np.min(d)) - 1.  # FIXME: 每一帧范围都不一样，有助于时间超分？\n",
    "        # d = 2. * (d - self.data_min) / (self.data_max - self.data_min) - 1.\n",
    "        d = d.reshape(self.dim[2],self.dim[1],self.dim[0])  # 以x变化最大的形式存放的，读取时需要倒过来读\n",
    "        d = d.transpose(2,1,0)  # 转化成xyz三维数组形式\n",
    "        return d\n",
    "\n",
    "    def _preload_worker(self, data_list, load_func, q, lock, idx_tqdm):\n",
    "        # Keep preloading data in parallel.\n",
    "        while True:\n",
    "            idx = q.get()\n",
    "            data_list[idx] = load_func(idx)\n",
    "            with lock:\n",
    "                idx_tqdm.update()\n",
    "            q.task_done()\n",
    "\n",
    "    def preload_with_multi_threads(self, load_func, num_workers, data_str='images'):\n",
    "        data_list = [None] * len(self.samples)\n",
    "\n",
    "        q = queue.Queue(maxsize=len(self.samples))\n",
    "        idx_tqdm = tqdm.tqdm(range(len(self.samples)), desc=f\"Loading {data_str}\", leave=False)\n",
    "        for i in range(len(self.samples)):\n",
    "            q.put(i)\n",
    "        lock = threading.Lock()\n",
    "        for ti in range(num_workers):\n",
    "            t = threading.Thread(target=self._preload_worker,\n",
    "                                    args=(data_list, load_func, q, lock, idx_tqdm), daemon=True)\n",
    "            t.start()\n",
    "        q.join()\n",
    "        idx_tqdm.close()\n",
    "        assert all(map(lambda x: x is not None, data_list))\n",
    "\n",
    "        return data_list  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df180441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class SineLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                 is_first=False, omega_0=30):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features, \n",
    "                                             1 / self.in_features)      \n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n",
    "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return torch.sin(self.omega_0 * self.linear(input))\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self,in_features,out_features,nonlinearity='relu'):\n",
    "        super(ResBlock,self).__init__()\n",
    "\n",
    "        self.net = []\n",
    "\n",
    "        self.net.append(SineLayer(in_features,out_features))\n",
    "\n",
    "        self.net.append(SineLayer(out_features,out_features))\n",
    "\n",
    "        self.flag = (in_features!=out_features)\n",
    "\n",
    "        if self.flag:\n",
    "            self.transform = SineLayer(in_features,out_features)\n",
    "\n",
    "        self.net = nn.Sequential(*self.net)\n",
    "    \n",
    "    def forward(self,features):\n",
    "        outputs = self.net(features)\n",
    "        if self.flag:\n",
    "            features = self.transform(features)\n",
    "        return 0.5*(outputs+features)\n",
    "\n",
    "class CoordNet(nn.Module):\n",
    "    def __init__(self, in_features, out_features, init_features,num_res):\n",
    "        super(CoordNet,self).__init__()\n",
    "\n",
    "        self.num_res = num_res\n",
    "\n",
    "        self.net1 = []\n",
    "        self.net1.append(ResBlock(in_features,init_features))\n",
    "        self.net1.append(ResBlock(init_features,2*init_features))\n",
    "        self.net1.append(ResBlock(2*init_features,4*init_features))\n",
    "        for i in range(self.num_res):\n",
    "            self.net1.append(ResBlock(4*init_features,4*init_features))\n",
    "        self.net1 = nn.Sequential(*self.net1)\n",
    "\n",
    "        self.net2 = []\n",
    "        self.net2.append(ResBlock(in_features,init_features))\n",
    "        self.net2.append(ResBlock(init_features,2*init_features))\n",
    "        self.net2.append(ResBlock(2*init_features,4*init_features))\n",
    "        for i in range(self.num_res):\n",
    "            self.net2.append(ResBlock(4*init_features,4*init_features))\n",
    "        self.net2 = nn.Sequential(*self.net2)\n",
    "\n",
    "        self.gate1 = nn.Linear(in_features, 3, bias=False)\n",
    "        self.gate2 = nn.Linear(in_features, 3, bias=False)\n",
    "\n",
    "        self.fc1 = ResBlock(4*init_features, out_features)\n",
    "        self.fc2 = ResBlock(4*init_features, out_features)\n",
    "        \n",
    "        self.gate_w_dat = []\n",
    "        self.gate_w_var = []\n",
    "\n",
    "    def forward(self, coords):\n",
    "        output1 = self.net1(coords)\n",
    "        output2 = self.net2(coords)\n",
    "        g1 = F.softmax(self.gate1(coords), dim=1)\n",
    "        g2 = F.softmax(self.gate2(coords), dim=1)\n",
    "#         self.gate_w_dat.append(g1[:, 2:3])\n",
    "#         self.gate_w_var.append(g2[:, 2:3])\n",
    "        out = self.fc1(g1[:, 0:1] * output1 + g1[:, 1:2] * output2)\n",
    "        var = self.fc2(g2[:, 0:1] * output1 + g2[:, 1:2] * output2) \n",
    "        var = F.softplus(var)\n",
    "#         gate_w_dat = self.gate_w_dat\n",
    "#         gate_w_var = self.gate_w_var\n",
    "        return out, var#, gate_w_dat, gate_w_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f11e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from datetime import datetime\n",
    "from shutil import copy, copytree\n",
    "import json\n",
    "import time\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import math\n",
    "\n",
    "class CorrLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CorrLoss,self).__init__()\n",
    "    def forward(self,y_true, y_pred):\n",
    "        num = torch.mean((y_true -torch.mean(y_true))*(y_pred - torch.mean(y_pred)))\n",
    "        den = torch.std(y_true)* torch.std(y_pred) + 1e-8\n",
    "        correlation =num/den\n",
    "        return 1-correlation\n",
    "\n",
    "def trainNet(model,args,dataset):\n",
    "    result_dir = os.path.join(args.result_dir, f'{args.dataset}', f'MMOE')\n",
    "\n",
    "    logs_dir = os.path.join(result_dir, 'logs')\n",
    "    checkpoints_dir = os.path.join(result_dir, 'checkpoints')\n",
    "    outputs_dir = os.path.join(result_dir, 'outputs')\n",
    "    os.makedirs(logs_dir, exist_ok=True)\n",
    "    os.makedirs(checkpoints_dir, exist_ok=True)\n",
    "    os.makedirs(outputs_dir, exist_ok=True)\n",
    "    \n",
    "    loss_log_file = result_dir+'/'+'loss-'+'-'+str(args.interval)+'-'+'-'+str(args.active)+'.txt'\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, betas=(0.9,0.999), weight_decay=1e-6, fused=True)\n",
    "    mse_loss = nn.MSELoss()\n",
    "    corr_loss = CorrLoss()\n",
    "    scaler = GradScaler(enabled=args.fp16)\n",
    "    \n",
    "    t = 0\n",
    "    start_time = time.time()\n",
    "    corr_losses = []\n",
    "    mse_losses = []\n",
    "    with open(loss_log_file,\"a\") as f:\n",
    "        f.write(f\"time:{time.time()}\")\n",
    "        f.write('\\n')\n",
    "    for epoch in range(1,args.num_epochs+1):\n",
    "        model.train()\n",
    "        training_data_inputs, training_data_outputs, batchIndexGenerator = dataset.get_data()\n",
    "        loss_mse = 0\n",
    "        loss_corr = 0\n",
    "        loop = tqdm.tqdm(batchIndexGenerator)\n",
    "        \n",
    "        for current_idx, next_idx in loop:\n",
    "            coord = training_data_inputs[current_idx:next_idx].contiguous()\n",
    "            v = training_data_outputs[current_idx:next_idx].contiguous()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast(enabled=args.fp16):\n",
    "                mean, var = model(coord)\n",
    "                var = var.view(-1) + 1.e-9\n",
    "                mse = mse_loss(mean.view(-1),v.view(-1)) \n",
    "                corr = corr_loss(var.view(-1), ((mean.view(-1)-v.view(-1))**2))\n",
    "                \n",
    "                if epoch>2:\n",
    "                    mu_corr = sum(corr_losses) / len(corr_losses)\n",
    "                    mu_mse = sum(mse_losses) / len(mse_losses)\n",
    "\n",
    "                    sigma_corr = torch.std(torch.tensor(corr_losses))\n",
    "                    sigma_mse = torch.std(torch.tensor(mse_losses))\n",
    "                    a_corr = sigma_corr / mu_corr\n",
    "                    a_mse = sigma_mse / mu_mse\n",
    "                    loss = a_mse*mse + a_corr*0.0008*corr\n",
    "                    \n",
    "                else:\n",
    "                    a_corr=1\n",
    "                    a_mse=1\n",
    "                    loss =  mse+0.0001*(corr)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            loss_mse += mse.mean().item()\n",
    "            loss_corr += corr.mean().item()\n",
    "\n",
    "            loop.set_description(f'Epoch [{epoch}/{args.num_epochs}]')\n",
    "            loop.set_postfix(mse=loss_mse, corr=loss_corr)\n",
    "        adjust_lr(args, optimizer, epoch)\n",
    "        mse_losses.append(loss_mse)\n",
    "        corr_losses.append(loss_corr)\n",
    "        # scheduler.step()\n",
    "\n",
    "        with open(loss_log_file,\"a\") as f:\n",
    "            f.write(f\"{epoch} {loss_mse} {loss_corr} {a_corr} {a_mse}\")\n",
    "            f.write('\\n')\n",
    "\n",
    "        if epoch%args.checkpoint == 0 or epoch==1:\n",
    "            torch.save(model.state_dict(),checkpoints_dir+'/'+'-'+str(args.interval)+'-'+'-'+str(epoch)+'.pth')\n",
    "    with open(loss_log_file,\"a\") as f:\n",
    "        f.write(f\"time:{time.time()}\")\n",
    "        f.write(f\"time:{time.time()-start_time}\")\n",
    "        f.write('\\n')\n",
    "\n",
    "@torch.no_grad()\n",
    "def inf(model,dataset,args, result_dir=None):\n",
    "    ckpt = './'+args.dataset+args.ckpt\n",
    "    result_dir = os.path.dirname(os.path.dirname(ckpt)) if result_dir is None else result_dir\n",
    "    outputs_dir = os.path.join(result_dir, 'outputs', 'inference')\n",
    "    var_dir = os.path.join(result_dir, 'outputs', 'var')\n",
    "    os.makedirs(outputs_dir, exist_ok=True)\n",
    "    os.makedirs(var_dir, exist_ok=True)\n",
    "\n",
    "    model.eval()\n",
    "    samples = dataset.samples\n",
    "    for i in range(len(samples)):  \n",
    "        for j in range(0,dataset.interval+1):\n",
    "            frame_idx = samples[i] + j\n",
    "            val_data_inputs, batchIndexGenerator =dataset._get_testing_data(frame_idx)\n",
    "            v = []\n",
    "            d = []\n",
    "            loop = tqdm.tqdm(batchIndexGenerator)\n",
    "            for current_idx, next_idx in loop:\n",
    "                coord = val_data_inputs[current_idx:next_idx]\n",
    "                with torch.no_grad():\n",
    "                    dat, var = model(coord)\n",
    "                    dat = dat.view(-1)\n",
    "                    var = var.view(-1)\n",
    "                    d.append(dat)\n",
    "                    v.append(var)\n",
    "            d = torch.cat(d,dim=-1).float()\n",
    "            d = d.detach().cpu().numpy()\n",
    "            d = np.asarray(d,dtype='<f')\n",
    "            out_path = f'{outputs_dir}/{frame_idx:04}.dat'\n",
    "            d.tofile(out_path, format='<f')\n",
    "            v = torch.cat(v,dim=-1).float()\n",
    "            v = v.detach().cpu().numpy()\n",
    "            v = np.asarray(v,dtype='<f')\n",
    "            var_path = f'{var_dir}/{frame_idx:04}.dat'\n",
    "            v.tofile(var_path, format='<f')\n",
    "    \n",
    "#     import matplotlib.pyplot as plt\n",
    "#     gate_w_dat = torch.cat(gate_w_dat, dim=0).cpu().numpy()  # 将 gate_w_dat 转换为 NumPy 数组\n",
    "#     gate_w_var = torch.cat(gate_w_var, dim=0).cpu().numpy()  # 将 gate_w_var 转换为 NumPy 数组\n",
    "#     print(np.min(gate_w_dat))\n",
    "#     print(np.max(gate_w_dat))\n",
    "    \n",
    "#     counts, bin_edges = np.histogram(gate_w_dat, bins=30)\n",
    "#     # 归一化高度，使得所有bin的高度之和为1\n",
    "#     probabilities = counts / counts.sum()\n",
    "#     # 绘制直方图\n",
    "#     plt.bar(bin_edges[:-1], probabilities, width=np.diff(bin_edges), color='skyblue', edgecolor='black', alpha=0.7)\n",
    "#     plt.title('Data Reconstruction Task of the Combustion Dataset')\n",
    "#     plt.xlabel('Value')\n",
    "#     plt.ylabel('Probability')\n",
    "#     max_value = np.max(gate_w_dat)\n",
    "#     min_value = np.min(gate_w_dat)\n",
    "#     plt.text(0.95, 0.95, f'Max: {max_value:.3f}\\nMin: {min_value:.3f}', \n",
    "#              horizontalalignment='right', verticalalignment='top', \n",
    "#              transform=plt.gca().transAxes, fontsize=12, color='black', bbox=dict(facecolor='white', alpha=0.5))\n",
    "#     plt.show()\n",
    "    \n",
    "#     counts, bin_edges = np.histogram(gate_w_var, bins=30)\n",
    "#     # 归一化高度，使得所有bin的高度之和为1\n",
    "#     probabilities = counts / counts.sum()\n",
    "#     # 绘制直方图\n",
    "#     plt.bar(bin_edges[:-1], probabilities, width=np.diff(bin_edges), color='coral', edgecolor='black', alpha=0.7)\n",
    "#     plt.title('Uncertainty Quantification Task of the Combustion Dataset')\n",
    "#     plt.xlabel('Value')\n",
    "#     plt.ylabel('Probability')\n",
    "#     max_value = np.max(gate_w_var)\n",
    "#     min_value = np.min(gate_w_var)\n",
    "#     plt.text(0.95, 0.95, f'Max: {max_value:.3f}\\nMin: {min_value:.3f}', \n",
    "#              horizontalalignment='right', verticalalignment='top', \n",
    "#              transform=plt.gca().transAxes, fontsize=12, color='black', bbox=dict(facecolor='white', alpha=0.5))\n",
    "#     plt.show()\n",
    "\n",
    "def adjust_lr(args, optimizer, epoch):\n",
    "    if args.lr_s=='exp':\n",
    "        lr = args.lr * math.exp(-0.02 * epoch)\n",
    "    elif args.lr_s=='step':\n",
    "        lr = args.lr * (0.5 ** (epoch // 50))\n",
    "    elif args.lr_s == 'cosine':\n",
    "        T_max = args.num_epochs\n",
    "        eta_min = 0\n",
    "        lr = eta_min + (args.lr - eta_min) * (1 + math.cos(math.pi * epoch / T_max)) / 2\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9c04af3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP16 enbled:  False\n",
      "Compile enbled:  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 263/263 [00:00<00:00, 328.49it/s]\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "p = argparse.ArgumentParser()\n",
    "p.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "p.add_argument('--gpu', type=str,default='0')\n",
    "p.add_argument('--seed', type=int, default=42)\n",
    "p.add_argument('--fp16', action=\"store_true\")\n",
    "p.add_argument('--compile', action=\"store_true\")\n",
    "# General training options\n",
    "p.add_argument('--downsample_factor', type=int, default=4, metavar='N',\n",
    "                    help='downsample factor')\n",
    "p.add_argument('--batch_size', type=int, default=8000)\n",
    "p.add_argument('--lr', type=float, default=1e-5, help='learning rate. default=1e-4')\n",
    "p.add_argument('--num_epochs', type=int, default=200,\n",
    "               help='Number of epochs to train for.')\n",
    "p.add_argument('--checkpoint', type=int, default=50,\n",
    "               help='checkpoint is saved.')\n",
    "p.add_argument('--ckpt', type=str,default=\"/MMOE/checkpoints/-0--200.pth\",\n",
    "               help='checkpoint path.')\n",
    "p.add_argument('--dataset', type=str, default='fivejets',\n",
    "               help='Scalar dataset; one of (Vortex, combustion)')\n",
    "p.add_argument('--result_dir', type=str, default='./', metavar='N',\n",
    "                    help='the path where we stored the synthesized data')\n",
    "p.add_argument('--interval', type=int, default=0, metavar='N',\n",
    "                    help='temporal upscaling factor')\n",
    "p.add_argument('--active', type=str, default='sine', metavar='N',\n",
    "                    help='active function')\n",
    "p.add_argument('--lr_s', type=str, default='cosine', help='step or exp')\n",
    "p.add_argument('--pre', type=str, default=0, metavar='N',\n",
    "                    help='pre-train')\n",
    "p.add_argument('--mode', type=str, default='inf', metavar='N',\n",
    "                    help='the path where we stored the synthesized data')\n",
    "opt = p.parse_known_args()[0]\n",
    "\n",
    "\n",
    "import torch\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = opt.gpu\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]  =  \"TRUE\"\n",
    "\n",
    "opt.cuda = not opt.no_cuda and torch.cuda.is_available()\n",
    "seed_everything(opt.seed)\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "def main():\n",
    "    print('FP16 enbled: ', opt.fp16)\n",
    "    print('Compile enbled: ', opt.compile)\n",
    "    Data = ScalarDataSet(opt)\n",
    "    Model = CoordNet(4,1, init_features=45, num_res=7)\n",
    "    if opt.mode in ['inf', 'ue']:\n",
    "        \n",
    "        ckpt = './'+opt.dataset+opt.ckpt\n",
    "        Model.load_state_dict(torch.load(ckpt))\n",
    "    if opt.compile:\n",
    "        Model.compile()\n",
    "    Model.cuda()\n",
    "\n",
    "    if opt.mode == 'train':\n",
    "        print('Initalize Model Successfully using Sine Function!')\n",
    "        trainNet(Model,opt,Data)\n",
    "    elif opt.mode == 'inf':\n",
    "        inf(Model, Data,opt)\n",
    "    \n",
    "if __name__== \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52d3cad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到误差\n",
    "import os\n",
    "import numpy as np\n",
    "data_name = 'fivejets'\n",
    "file = 'MMOE'\n",
    "origin_dir = './dataset/' + data_name + '/'\n",
    "recons_dir = './' + data_name + '/' + file + '/outputs/inference/'\n",
    "error_dir = './' + data_name + '/' + file + '/outputs/error/'\n",
    "var_dir = './' + data_name + '/' + file + '/outputs/var/'\n",
    "os.makedirs(error_dir, exist_ok=True)\n",
    "for i in range(1,2):\n",
    "    d = np.fromfile(recons_dir + '{:04d}.dat'.format(i), dtype='<f')\n",
    "    real = np.fromfile(origin_dir + '{:04d}.raw'.format(i), dtype='<f')\n",
    "    real = 2*(real-np.min(real))/(np.max(real)-np.min(real))-1\n",
    "    error = (real - d) ** 2    \n",
    "    error.tofile(error_dir+'{:04d}.dat'.format(i), format='<f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0207650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:46.232330322265625\n",
      "1:0.8252461154704082\n"
     ]
    }
   ],
   "source": [
    "#计算PSNR,norm\n",
    "import numpy as np\n",
    "import torch\n",
    "psnr = 0\n",
    "k=0\n",
    "psnr_fn_paper = lambda gt, pred, diff: 10. * torch.log10(diff**2 / torch.mean((gt-pred)**2))\n",
    "for i in range(1,2):\n",
    "    gt = np.fromfile(origin_dir + '{:04d}.raw'.format(i),dtype=np.float32)\n",
    "    d = np.fromfile(recons_dir + \"{:04d}.dat\".format(i),dtype=np.float32)\n",
    "    gt = 2*(gt-np.min(gt))/(np.max(gt)-np.min(gt))-1\n",
    "    d = torch.from_numpy(d)\n",
    "    gt = torch.from_numpy(gt)    \n",
    "    diff = gt.max() - gt.min()\n",
    "    \n",
    "    psnr_volume = psnr_fn_paper(gt, d, diff)\n",
    "    print(str(i)+\":\"+str(psnr_volume.item()))\n",
    "    psnr+=psnr_volume.item()\n",
    "    k+=1\n",
    "# print(psnr/k)\n",
    "\n",
    "#计算corr,norm \n",
    "k = 0 \n",
    "t_corr = 0 \n",
    "for i in range(1,2): \n",
    "    k += 1 \n",
    "    v = np.fromfile(var_dir + \"{:04d}.dat\".format(i), dtype='<f') \n",
    "    e = np.fromfile(error_dir + \"{:04d}.dat\".format(i), dtype='<f') \n",
    "    corr = np.corrcoef(v, e)  \n",
    "    print(str(i)+\":\"+str(corr[0,1])) \n",
    "    t_corr+=corr[0,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dd977c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
